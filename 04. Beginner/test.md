# 全连接神经网络（数学描述）

**全连接网络**（也称为 **全连接层 / Dense 网络**）由多层神经元组成。  
在这种结构中，一层的每个神经元都与下一层的所有神经元相连接。

---

### (1) 输入层

$$
\mathbf{x} \in \mathbb{R}^{d}
$$

*输入向量，维度为 $d$。*

---

### (2) 线性变换

$$
\mathbf{z}^{(l)} = W^{(l)} \mathbf{a}^{(l-1)} + \mathbf{b}^{(l)}, 
\quad \mathbf{a}^{(0)} = \mathbf{x}
$$

*计算第 $l$ 层的线性组合（预激活值）。*

---

### (3) 激活函数

$$
\mathbf{a}^{(l)} = \sigma(\mathbf{z}^{(l)})
$$

*对线性结果逐元素施加激活函数。*

---

### (4) 输出层

$$
\mathbf{y} = \mathbf{a}^{(L)}
$$

*网络的最终输出。*  

- 在 **回归任务** 中，最后一层常用恒等函数作为激活；  
- 在 **二分类任务** 中，最后一层通常使用 sigmoid 激活；  
- 在 **多分类任务** 中，最后一层一般使用 softmax 激活。  
